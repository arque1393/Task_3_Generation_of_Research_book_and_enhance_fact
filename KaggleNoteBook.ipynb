{"cells":[{"cell_type":"markdown","metadata":{},"source":["#### Instal"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-02-15T05:06:08.590089Z","iopub.status.busy":"2024-02-15T05:06:08.589773Z","iopub.status.idle":"2024-02-15T05:06:28.229964Z","shell.execute_reply":"2024-02-15T05:06:28.229000Z","shell.execute_reply.started":"2024-02-15T05:06:08.590065Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install transformers datasets\n","!pip install huggingface_hub[cli]\n"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T05:10:18.360438Z","iopub.status.busy":"2024-02-15T05:10:18.360014Z","iopub.status.idle":"2024-02-15T05:10:18.668850Z","shell.execute_reply":"2024-02-15T05:10:18.667610Z","shell.execute_reply.started":"2024-02-15T05:10:18.360411Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.10.13\n"]}],"source":["!python --version"]},{"cell_type":"markdown","metadata":{},"source":["## New Book Name Generation With LLM"]},{"cell_type":"markdown","metadata":{},"source":["### List all Model Name That I have explored \n","- facebook/nllb-200-3.3B"]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-02-15T05:11:45.386048Z","iopub.status.busy":"2024-02-15T05:11:45.385709Z","iopub.status.idle":"2024-02-15T05:11:45.469421Z","shell.execute_reply":"2024-02-15T05:11:45.467833Z","shell.execute_reply.started":"2024-02-15T05:11:45.386022Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"data":{"text/plain":["['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ALIGN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ALIGN_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ALTCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ALTCLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ASTConfig',\n"," 'ASTFeatureExtractor',\n"," 'ASTForAudioClassification',\n"," 'ASTModel',\n"," 'ASTPreTrainedModel',\n"," 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'AUTOFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'AUTOFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'Adafactor',\n"," 'AdamW',\n"," 'AdamWeightDecay',\n"," 'AdaptiveEmbedding',\n"," 'AddedToken',\n"," 'Agent',\n"," 'AlbertConfig',\n"," 'AlbertForMaskedLM',\n"," 'AlbertForMultipleChoice',\n"," 'AlbertForPreTraining',\n"," 'AlbertForQuestionAnswering',\n"," 'AlbertForSequenceClassification',\n"," 'AlbertForTokenClassification',\n"," 'AlbertModel',\n"," 'AlbertPreTrainedModel',\n"," 'AlbertTokenizer',\n"," 'AlbertTokenizerFast',\n"," 'AlignConfig',\n"," 'AlignModel',\n"," 'AlignPreTrainedModel',\n"," 'AlignProcessor',\n"," 'AlignTextConfig',\n"," 'AlignTextModel',\n"," 'AlignVisionConfig',\n"," 'AlignVisionModel',\n"," 'AltCLIPConfig',\n"," 'AltCLIPModel',\n"," 'AltCLIPPreTrainedModel',\n"," 'AltCLIPProcessor',\n"," 'AltCLIPTextConfig',\n"," 'AltCLIPTextModel',\n"," 'AltCLIPVisionConfig',\n"," 'AltCLIPVisionModel',\n"," 'AlternatingCodebooksLogitsProcessor',\n"," 'AudioClassificationPipeline',\n"," 'AutoBackbone',\n"," 'AutoConfig',\n"," 'AutoFeatureExtractor',\n"," 'AutoImageProcessor',\n"," 'AutoModel',\n"," 'AutoModelForAudioClassification',\n"," 'AutoModelForAudioFrameClassification',\n"," 'AutoModelForAudioXVector',\n"," 'AutoModelForCTC',\n"," 'AutoModelForCausalLM',\n"," 'AutoModelForDepthEstimation',\n"," 'AutoModelForDocumentQuestionAnswering',\n"," 'AutoModelForImageClassification',\n"," 'AutoModelForImageSegmentation',\n"," 'AutoModelForImageToImage',\n"," 'AutoModelForInstanceSegmentation',\n"," 'AutoModelForMaskGeneration',\n"," 'AutoModelForMaskedImageModeling',\n"," 'AutoModelForMaskedLM',\n"," 'AutoModelForMultipleChoice',\n"," 'AutoModelForNextSentencePrediction',\n"," 'AutoModelForObjectDetection',\n"," 'AutoModelForPreTraining',\n"," 'AutoModelForQuestionAnswering',\n"," 'AutoModelForSemanticSegmentation',\n"," 'AutoModelForSeq2SeqLM',\n"," 'AutoModelForSequenceClassification',\n"," 'AutoModelForSpeechSeq2Seq',\n"," 'AutoModelForTableQuestionAnswering',\n"," 'AutoModelForTextEncoding',\n"," 'AutoModelForTextToSpectrogram',\n"," 'AutoModelForTextToWaveform',\n"," 'AutoModelForTokenClassification',\n"," 'AutoModelForUniversalSegmentation',\n"," 'AutoModelForVideoClassification',\n"," 'AutoModelForVision2Seq',\n"," 'AutoModelForVisualQuestionAnswering',\n"," 'AutoModelForZeroShotImageClassification',\n"," 'AutoModelForZeroShotObjectDetection',\n"," 'AutoModelWithLMHead',\n"," 'AutoProcessor',\n"," 'AutoTokenizer',\n"," 'AutoformerConfig',\n"," 'AutoformerForPrediction',\n"," 'AutoformerModel',\n"," 'AutoformerPreTrainedModel',\n"," 'AutomaticSpeechRecognitionPipeline',\n"," 'AwqConfig',\n"," 'AzureOpenAiAgent',\n"," 'BARK_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BART_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BIGBIRD_PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BIOGPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BIOGPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BLENDERBOT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BLENDERBOT_SMALL_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BLIP_2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BLIP_2_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BLOOM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BRIDGETOWER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BRIDGETOWER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BROS_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'BROS_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'BarkCausalModel',\n"," 'BarkCoarseConfig',\n"," 'BarkCoarseModel',\n"," 'BarkConfig',\n"," 'BarkFineConfig',\n"," 'BarkFineModel',\n"," 'BarkModel',\n"," 'BarkPreTrainedModel',\n"," 'BarkProcessor',\n"," 'BarkSemanticConfig',\n"," 'BarkSemanticModel',\n"," 'BartConfig',\n"," 'BartForCausalLM',\n"," 'BartForConditionalGeneration',\n"," 'BartForQuestionAnswering',\n"," 'BartForSequenceClassification',\n"," 'BartModel',\n"," 'BartPreTrainedModel',\n"," 'BartPretrainedModel',\n"," 'BartTokenizer',\n"," 'BartTokenizerFast',\n"," 'BarthezTokenizer',\n"," 'BarthezTokenizerFast',\n"," 'BartphoTokenizer',\n"," 'BasicTokenizer',\n"," 'BatchEncoding',\n"," 'BatchFeature',\n"," 'BeamScorer',\n"," 'BeamSearchScorer',\n"," 'BeitBackbone',\n"," 'BeitConfig',\n"," 'BeitFeatureExtractor',\n"," 'BeitForImageClassification',\n"," 'BeitForMaskedImageModeling',\n"," 'BeitForSemanticSegmentation',\n"," 'BeitImageProcessor',\n"," 'BeitModel',\n"," 'BeitPreTrainedModel',\n"," 'BertConfig',\n"," 'BertForMaskedLM',\n"," 'BertForMultipleChoice',\n"," 'BertForNextSentencePrediction',\n"," 'BertForPreTraining',\n"," 'BertForQuestionAnswering',\n"," 'BertForSequenceClassification',\n"," 'BertForTokenClassification',\n"," 'BertGenerationConfig',\n"," 'BertGenerationDecoder',\n"," 'BertGenerationEncoder',\n"," 'BertGenerationPreTrainedModel',\n"," 'BertGenerationTokenizer',\n"," 'BertJapaneseTokenizer',\n"," 'BertLMHeadModel',\n"," 'BertLayer',\n"," 'BertModel',\n"," 'BertPreTrainedModel',\n"," 'BertTokenizer',\n"," 'BertTokenizerFast',\n"," 'BertweetTokenizer',\n"," 'BigBirdConfig',\n"," 'BigBirdForCausalLM',\n"," 'BigBirdForMaskedLM',\n"," 'BigBirdForMultipleChoice',\n"," 'BigBirdForPreTraining',\n"," 'BigBirdForQuestionAnswering',\n"," 'BigBirdForSequenceClassification',\n"," 'BigBirdForTokenClassification',\n"," 'BigBirdLayer',\n"," 'BigBirdModel',\n"," 'BigBirdPegasusConfig',\n"," 'BigBirdPegasusForCausalLM',\n"," 'BigBirdPegasusForConditionalGeneration',\n"," 'BigBirdPegasusForQuestionAnswering',\n"," 'BigBirdPegasusForSequenceClassification',\n"," 'BigBirdPegasusModel',\n"," 'BigBirdPegasusPreTrainedModel',\n"," 'BigBirdPreTrainedModel',\n"," 'BigBirdTokenizer',\n"," 'BigBirdTokenizerFast',\n"," 'BioGptConfig',\n"," 'BioGptForCausalLM',\n"," 'BioGptForSequenceClassification',\n"," 'BioGptForTokenClassification',\n"," 'BioGptModel',\n"," 'BioGptPreTrainedModel',\n"," 'BioGptTokenizer',\n"," 'BitBackbone',\n"," 'BitConfig',\n"," 'BitForImageClassification',\n"," 'BitImageProcessor',\n"," 'BitModel',\n"," 'BitPreTrainedModel',\n"," 'BitsAndBytesConfig',\n"," 'BlenderbotConfig',\n"," 'BlenderbotForCausalLM',\n"," 'BlenderbotForConditionalGeneration',\n"," 'BlenderbotModel',\n"," 'BlenderbotPreTrainedModel',\n"," 'BlenderbotSmallConfig',\n"," 'BlenderbotSmallForCausalLM',\n"," 'BlenderbotSmallForConditionalGeneration',\n"," 'BlenderbotSmallModel',\n"," 'BlenderbotSmallPreTrainedModel',\n"," 'BlenderbotSmallTokenizer',\n"," 'BlenderbotSmallTokenizerFast',\n"," 'BlenderbotTokenizer',\n"," 'BlenderbotTokenizerFast',\n"," 'Blip2Config',\n"," 'Blip2ForConditionalGeneration',\n"," 'Blip2Model',\n"," 'Blip2PreTrainedModel',\n"," 'Blip2Processor',\n"," 'Blip2QFormerConfig',\n"," 'Blip2QFormerModel',\n"," 'Blip2VisionConfig',\n"," 'Blip2VisionModel',\n"," 'BlipConfig',\n"," 'BlipForConditionalGeneration',\n"," 'BlipForImageTextRetrieval',\n"," 'BlipForQuestionAnswering',\n"," 'BlipImageProcessor',\n"," 'BlipModel',\n"," 'BlipPreTrainedModel',\n"," 'BlipProcessor',\n"," 'BlipTextConfig',\n"," 'BlipTextModel',\n"," 'BlipVisionConfig',\n"," 'BlipVisionModel',\n"," 'BloomConfig',\n"," 'BloomForCausalLM',\n"," 'BloomForQuestionAnswering',\n"," 'BloomForSequenceClassification',\n"," 'BloomForTokenClassification',\n"," 'BloomModel',\n"," 'BloomPreTrainedModel',\n"," 'BloomTokenizerFast',\n"," 'BridgeTowerConfig',\n"," 'BridgeTowerForContrastiveLearning',\n"," 'BridgeTowerForImageAndTextRetrieval',\n"," 'BridgeTowerForMaskedLM',\n"," 'BridgeTowerImageProcessor',\n"," 'BridgeTowerModel',\n"," 'BridgeTowerPreTrainedModel',\n"," 'BridgeTowerProcessor',\n"," 'BridgeTowerTextConfig',\n"," 'BridgeTowerVisionConfig',\n"," 'BrosConfig',\n"," 'BrosForTokenClassification',\n"," 'BrosModel',\n"," 'BrosPreTrainedModel',\n"," 'BrosProcessor',\n"," 'BrosSpadeEEForTokenClassification',\n"," 'BrosSpadeELForTokenClassification',\n"," 'ByT5Tokenizer',\n"," 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CANINE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CANINE_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CHINESE_CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CHINESE_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CLAP_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CLIPConfig',\n"," 'CLIPFeatureExtractor',\n"," 'CLIPImageProcessor',\n"," 'CLIPModel',\n"," 'CLIPPreTrainedModel',\n"," 'CLIPProcessor',\n"," 'CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CLIPSegConfig',\n"," 'CLIPSegForImageSegmentation',\n"," 'CLIPSegModel',\n"," 'CLIPSegPreTrainedModel',\n"," 'CLIPSegProcessor',\n"," 'CLIPSegTextConfig',\n"," 'CLIPSegTextModel',\n"," 'CLIPSegVisionConfig',\n"," 'CLIPSegVisionModel',\n"," 'CLIPTextConfig',\n"," 'CLIPTextModel',\n"," 'CLIPTextModelWithProjection',\n"," 'CLIPTokenizer',\n"," 'CLIPTokenizerFast',\n"," 'CLIPVisionConfig',\n"," 'CLIPVisionModel',\n"," 'CLIPVisionModelWithProjection',\n"," 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CLVP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CLVP_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CODEGEN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CONDITIONAL_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CONDITIONAL_DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CONFIG_MAPPING',\n"," 'CONFIG_NAME',\n"," 'CONVBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CONVNEXTV2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CONVNEXTV2_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CONVNEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CONVNEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CPMANT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CPMANT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CTRLConfig',\n"," 'CTRLForSequenceClassification',\n"," 'CTRLLMHeadModel',\n"," 'CTRLModel',\n"," 'CTRLPreTrainedModel',\n"," 'CTRLTokenizer',\n"," 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'CVT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'CVT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'Cache',\n"," 'CamembertConfig',\n"," 'CamembertForCausalLM',\n"," 'CamembertForMaskedLM',\n"," 'CamembertForMultipleChoice',\n"," 'CamembertForQuestionAnswering',\n"," 'CamembertForSequenceClassification',\n"," 'CamembertForTokenClassification',\n"," 'CamembertModel',\n"," 'CamembertPreTrainedModel',\n"," 'CamembertTokenizer',\n"," 'CamembertTokenizerFast',\n"," 'CanineConfig',\n"," 'CanineForMultipleChoice',\n"," 'CanineForQuestionAnswering',\n"," 'CanineForSequenceClassification',\n"," 'CanineForTokenClassification',\n"," 'CanineLayer',\n"," 'CanineModel',\n"," 'CaninePreTrainedModel',\n"," 'CanineTokenizer',\n"," 'CharSpan',\n"," 'CharacterTokenizer',\n"," 'ChineseCLIPConfig',\n"," 'ChineseCLIPFeatureExtractor',\n"," 'ChineseCLIPImageProcessor',\n"," 'ChineseCLIPModel',\n"," 'ChineseCLIPPreTrainedModel',\n"," 'ChineseCLIPProcessor',\n"," 'ChineseCLIPTextConfig',\n"," 'ChineseCLIPTextModel',\n"," 'ChineseCLIPVisionConfig',\n"," 'ChineseCLIPVisionModel',\n"," 'ClapAudioConfig',\n"," 'ClapAudioModel',\n"," 'ClapAudioModelWithProjection',\n"," 'ClapConfig',\n"," 'ClapFeatureExtractor',\n"," 'ClapModel',\n"," 'ClapPreTrainedModel',\n"," 'ClapProcessor',\n"," 'ClapTextConfig',\n"," 'ClapTextModel',\n"," 'ClapTextModelWithProjection',\n"," 'ClassifierFreeGuidanceLogitsProcessor',\n"," 'ClvpConfig',\n"," 'ClvpDecoder',\n"," 'ClvpDecoderConfig',\n"," 'ClvpEncoder',\n"," 'ClvpEncoderConfig',\n"," 'ClvpFeatureExtractor',\n"," 'ClvpForCausalLM',\n"," 'ClvpModel',\n"," 'ClvpModelForConditionalGeneration',\n"," 'ClvpPreTrainedModel',\n"," 'ClvpProcessor',\n"," 'ClvpTokenizer',\n"," 'CodeGenConfig',\n"," 'CodeGenForCausalLM',\n"," 'CodeGenModel',\n"," 'CodeGenPreTrainedModel',\n"," 'CodeGenTokenizer',\n"," 'CodeGenTokenizerFast',\n"," 'CodeLlamaTokenizer',\n"," 'CodeLlamaTokenizerFast',\n"," 'ConditionalDetrConfig',\n"," 'ConditionalDetrFeatureExtractor',\n"," 'ConditionalDetrForObjectDetection',\n"," 'ConditionalDetrForSegmentation',\n"," 'ConditionalDetrImageProcessor',\n"," 'ConditionalDetrModel',\n"," 'ConditionalDetrPreTrainedModel',\n"," 'ConstrainedBeamSearchScorer',\n"," 'Constraint',\n"," 'ConstraintListState',\n"," 'Conv1D',\n"," 'ConvBertConfig',\n"," 'ConvBertForMaskedLM',\n"," 'ConvBertForMultipleChoice',\n"," 'ConvBertForQuestionAnswering',\n"," 'ConvBertForSequenceClassification',\n"," 'ConvBertForTokenClassification',\n"," 'ConvBertLayer',\n"," 'ConvBertModel',\n"," 'ConvBertPreTrainedModel',\n"," 'ConvBertTokenizer',\n"," 'ConvBertTokenizerFast',\n"," 'ConvNextBackbone',\n"," 'ConvNextConfig',\n"," 'ConvNextFeatureExtractor',\n"," 'ConvNextForImageClassification',\n"," 'ConvNextImageProcessor',\n"," 'ConvNextModel',\n"," 'ConvNextPreTrainedModel',\n"," 'ConvNextV2Backbone',\n"," 'ConvNextV2Config',\n"," 'ConvNextV2ForImageClassification',\n"," 'ConvNextV2Model',\n"," 'ConvNextV2PreTrainedModel',\n"," 'Conversation',\n"," 'ConversationalPipeline',\n"," 'CpmAntConfig',\n"," 'CpmAntForCausalLM',\n"," 'CpmAntModel',\n"," 'CpmAntPreTrainedModel',\n"," 'CpmAntTokenizer',\n"," 'CpmTokenizer',\n"," 'CpmTokenizerFast',\n"," 'CsvPipelineDataFormat',\n"," 'CvtConfig',\n"," 'CvtForImageClassification',\n"," 'CvtModel',\n"," 'CvtPreTrainedModel',\n"," 'DATA2VEC_AUDIO_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DATA2VEC_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DATA2VEC_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DATA2VEC_VISION_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DATA2VEC_VISION_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DEBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DEBERTA_V2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DECISION_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DECISION_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DEFORMABLE_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DEFORMABLE_DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DETA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DETA_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DINAT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DINAT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DINOV2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DINOV2_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DONUT_SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DONUT_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DPRConfig',\n"," 'DPRContextEncoder',\n"," 'DPRContextEncoderTokenizer',\n"," 'DPRContextEncoderTokenizerFast',\n"," 'DPRPreTrainedModel',\n"," 'DPRPretrainedContextEncoder',\n"," 'DPRPretrainedQuestionEncoder',\n"," 'DPRPretrainedReader',\n"," 'DPRQuestionEncoder',\n"," 'DPRQuestionEncoderTokenizer',\n"," 'DPRQuestionEncoderTokenizerFast',\n"," 'DPRReader',\n"," 'DPRReaderOutput',\n"," 'DPRReaderTokenizer',\n"," 'DPRReaderTokenizerFast',\n"," 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'DPTConfig',\n"," 'DPTFeatureExtractor',\n"," 'DPTForDepthEstimation',\n"," 'DPTForSemanticSegmentation',\n"," 'DPTImageProcessor',\n"," 'DPTModel',\n"," 'DPTPreTrainedModel',\n"," 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'Data2VecAudioConfig',\n"," 'Data2VecAudioForAudioFrameClassification',\n"," 'Data2VecAudioForCTC',\n"," 'Data2VecAudioForSequenceClassification',\n"," 'Data2VecAudioForXVector',\n"," 'Data2VecAudioModel',\n"," 'Data2VecAudioPreTrainedModel',\n"," 'Data2VecTextConfig',\n"," 'Data2VecTextForCausalLM',\n"," 'Data2VecTextForMaskedLM',\n"," 'Data2VecTextForMultipleChoice',\n"," 'Data2VecTextForQuestionAnswering',\n"," 'Data2VecTextForSequenceClassification',\n"," 'Data2VecTextForTokenClassification',\n"," 'Data2VecTextModel',\n"," 'Data2VecTextPreTrainedModel',\n"," 'Data2VecVisionConfig',\n"," 'Data2VecVisionForImageClassification',\n"," 'Data2VecVisionForSemanticSegmentation',\n"," 'Data2VecVisionModel',\n"," 'Data2VecVisionPreTrainedModel',\n"," 'DataCollator',\n"," 'DataCollatorForLanguageModeling',\n"," 'DataCollatorForPermutationLanguageModeling',\n"," 'DataCollatorForSOP',\n"," 'DataCollatorForSeq2Seq',\n"," 'DataCollatorForTokenClassification',\n"," 'DataCollatorForWholeWordMask',\n"," 'DataCollatorWithPadding',\n"," 'DataProcessor',\n"," 'DebertaConfig',\n"," 'DebertaForMaskedLM',\n"," 'DebertaForQuestionAnswering',\n"," 'DebertaForSequenceClassification',\n"," 'DebertaForTokenClassification',\n"," 'DebertaModel',\n"," 'DebertaPreTrainedModel',\n"," 'DebertaTokenizer',\n"," 'DebertaTokenizerFast',\n"," 'DebertaV2Config',\n"," 'DebertaV2ForMaskedLM',\n"," 'DebertaV2ForMultipleChoice',\n"," 'DebertaV2ForQuestionAnswering',\n"," 'DebertaV2ForSequenceClassification',\n"," 'DebertaV2ForTokenClassification',\n"," 'DebertaV2Model',\n"," 'DebertaV2PreTrainedModel',\n"," 'DebertaV2Tokenizer',\n"," 'DebertaV2TokenizerFast',\n"," 'DecisionTransformerConfig',\n"," 'DecisionTransformerGPT2Model',\n"," 'DecisionTransformerGPT2PreTrainedModel',\n"," 'DecisionTransformerModel',\n"," 'DecisionTransformerPreTrainedModel',\n"," 'DefaultDataCollator',\n"," 'DefaultFlowCallback',\n"," 'DeformableDetrConfig',\n"," 'DeformableDetrFeatureExtractor',\n"," 'DeformableDetrForObjectDetection',\n"," 'DeformableDetrImageProcessor',\n"," 'DeformableDetrModel',\n"," 'DeformableDetrPreTrainedModel',\n"," 'DeiTConfig',\n"," 'DeiTFeatureExtractor',\n"," 'DeiTForImageClassification',\n"," 'DeiTForImageClassificationWithTeacher',\n"," 'DeiTForMaskedImageModeling',\n"," 'DeiTImageProcessor',\n"," 'DeiTModel',\n"," 'DeiTPreTrainedModel',\n"," 'DepthEstimationPipeline',\n"," 'DetaConfig',\n"," 'DetaForObjectDetection',\n"," 'DetaImageProcessor',\n"," 'DetaModel',\n"," 'DetaPreTrainedModel',\n"," 'DetrConfig',\n"," 'DetrFeatureExtractor',\n"," 'DetrForObjectDetection',\n"," 'DetrForSegmentation',\n"," 'DetrImageProcessor',\n"," 'DetrModel',\n"," 'DetrPreTrainedModel',\n"," 'DinatBackbone',\n"," 'DinatConfig',\n"," 'DinatForImageClassification',\n"," 'DinatModel',\n"," 'DinatPreTrainedModel',\n"," 'Dinov2Backbone',\n"," 'Dinov2Config',\n"," 'Dinov2ForImageClassification',\n"," 'Dinov2Model',\n"," 'Dinov2PreTrainedModel',\n"," 'DisjunctiveConstraint',\n"," 'DistilBertConfig',\n"," 'DistilBertForMaskedLM',\n"," 'DistilBertForMultipleChoice',\n"," 'DistilBertForQuestionAnswering',\n"," 'DistilBertForSequenceClassification',\n"," 'DistilBertForTokenClassification',\n"," 'DistilBertModel',\n"," 'DistilBertPreTrainedModel',\n"," 'DistilBertTokenizer',\n"," 'DistilBertTokenizerFast',\n"," 'DocumentQuestionAnsweringPipeline',\n"," 'DonutFeatureExtractor',\n"," 'DonutImageProcessor',\n"," 'DonutProcessor',\n"," 'DonutSwinConfig',\n"," 'DonutSwinModel',\n"," 'DonutSwinPreTrainedModel',\n"," 'DummyObject',\n"," 'DynamicCache',\n"," 'EFFICIENTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'EFFICIENTNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'EFFICIENTNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ENCODEC_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ENCODEC_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ERNIE_M_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ERNIE_M_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ERNIE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ERNIE_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'ESM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'ESM_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'EarlyStoppingCallback',\n"," 'EfficientFormerConfig',\n"," 'EfficientFormerForImageClassification',\n"," 'EfficientFormerForImageClassificationWithTeacher',\n"," 'EfficientFormerImageProcessor',\n"," 'EfficientFormerModel',\n"," 'EfficientFormerPreTrainedModel',\n"," 'EfficientNetConfig',\n"," 'EfficientNetForImageClassification',\n"," 'EfficientNetImageProcessor',\n"," 'EfficientNetModel',\n"," 'EfficientNetPreTrainedModel',\n"," 'ElectraConfig',\n"," 'ElectraForCausalLM',\n"," 'ElectraForMaskedLM',\n"," 'ElectraForMultipleChoice',\n"," 'ElectraForPreTraining',\n"," 'ElectraForQuestionAnswering',\n"," 'ElectraForSequenceClassification',\n"," 'ElectraForTokenClassification',\n"," 'ElectraModel',\n"," 'ElectraPreTrainedModel',\n"," 'ElectraTokenizer',\n"," 'ElectraTokenizerFast',\n"," 'EncodecConfig',\n"," 'EncodecFeatureExtractor',\n"," 'EncodecModel',\n"," 'EncodecPreTrainedModel',\n"," 'EncoderDecoderConfig',\n"," 'EncoderDecoderModel',\n"," 'EncoderNoRepeatNGramLogitsProcessor',\n"," 'EncoderRepetitionPenaltyLogitsProcessor',\n"," 'EpsilonLogitsWarper',\n"," 'ErnieConfig',\n"," 'ErnieForCausalLM',\n"," 'ErnieForMaskedLM',\n"," 'ErnieForMultipleChoice',\n"," 'ErnieForNextSentencePrediction',\n"," 'ErnieForPreTraining',\n"," 'ErnieForQuestionAnswering',\n"," 'ErnieForSequenceClassification',\n"," 'ErnieForTokenClassification',\n"," 'ErnieMConfig',\n"," 'ErnieMForInformationExtraction',\n"," 'ErnieMForMultipleChoice',\n"," 'ErnieMForQuestionAnswering',\n"," 'ErnieMForSequenceClassification',\n"," 'ErnieMForTokenClassification',\n"," 'ErnieMModel',\n"," 'ErnieMPreTrainedModel',\n"," 'ErnieMTokenizer',\n"," 'ErnieModel',\n"," 'ErniePreTrainedModel',\n"," 'EsmConfig',\n"," 'EsmFoldPreTrainedModel',\n"," 'EsmForMaskedLM',\n"," 'EsmForProteinFolding',\n"," 'EsmForSequenceClassification',\n"," 'EsmForTokenClassification',\n"," 'EsmModel',\n"," 'EsmPreTrainedModel',\n"," 'EsmTokenizer',\n"," 'EtaLogitsWarper',\n"," 'EvalPrediction',\n"," 'ExponentialDecayLengthPenalty',\n"," 'FALCON_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FALCON_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FASTSPEECH2_CONFORMER_HIFIGAN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FASTSPEECH2_CONFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FASTSPEECH2_CONFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FASTSPEECH2_CONFORMER_WITH_HIFIGAN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FEATURE_EXTRACTOR_MAPPING',\n"," 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FLAVA_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FLAX_MODEL_FOR_AUDIO_CLASSIFICATION_MAPPING',\n"," 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING',\n"," 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING',\n"," 'FLAX_MODEL_FOR_MASKED_LM_MAPPING',\n"," 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING',\n"," 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING',\n"," 'FLAX_MODEL_FOR_PRETRAINING_MAPPING',\n"," 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n"," 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n"," 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING',\n"," 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING',\n"," 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n"," 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING',\n"," 'FLAX_MODEL_MAPPING',\n"," 'FLAX_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FNetConfig',\n"," 'FNetForMaskedLM',\n"," 'FNetForMultipleChoice',\n"," 'FNetForNextSentencePrediction',\n"," 'FNetForPreTraining',\n"," 'FNetForQuestionAnswering',\n"," 'FNetForSequenceClassification',\n"," 'FNetForTokenClassification',\n"," 'FNetLayer',\n"," 'FNetModel',\n"," 'FNetPreTrainedModel',\n"," 'FNetTokenizer',\n"," 'FNetTokenizerFast',\n"," 'FOCALNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FOCALNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FSMTConfig',\n"," 'FSMTForConditionalGeneration',\n"," 'FSMTModel',\n"," 'FSMTTokenizer',\n"," 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FUNNEL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST',\n"," 'FUYU_PRETRAINED_CONFIG_ARCHIVE_MAP',\n"," 'FalconConfig',\n"," 'FalconForCausalLM',\n"," 'FalconForQuestionAnswering',\n"," 'FalconForSequenceClassification',\n"," 'FalconForTokenClassification',\n"," 'FalconModel',\n"," 'FalconPreTrainedModel',\n"," 'FastSpeech2ConformerConfig',\n"," 'FastSpeech2ConformerHifiGan',\n"," 'FastSpeech2ConformerHifiGanConfig',\n"," 'FastSpeech2ConformerModel',\n"," 'FastSpeech2ConformerPreTrainedModel',\n"," 'FastSpeech2ConformerTokenizer',\n"," 'FastSpeech2ConformerWithHifiGan',\n"," 'FastSpeech2ConformerWithHifiGanConfig',\n"," 'FeatureExtractionMixin',\n"," 'FeatureExtractionPipeline',\n"," 'FillMaskPipeline',\n"," 'FlaubertConfig',\n"," 'FlaubertForMultipleChoice',\n"," 'FlaubertForQuestionAnswering',\n"," 'FlaubertForQuestionAnsweringSimple',\n"," 'FlaubertForSequenceClassification',\n"," 'FlaubertForTokenClassification',\n"," 'FlaubertModel',\n"," 'FlaubertPreTrainedModel',\n"," 'FlaubertTokenizer',\n"," 'FlaubertWithLMHeadModel',\n"," 'FlavaConfig',\n"," 'FlavaFeatureExtractor',\n"," 'FlavaForPreTraining',\n"," 'FlavaImageCodebook',\n"," 'FlavaImageCodebookConfig',\n"," 'FlavaImageConfig',\n"," 'FlavaImageModel',\n"," 'FlavaImageProcessor',\n"," 'FlavaModel',\n"," 'FlavaMultimodalConfig',\n"," 'FlavaMultimodalModel',\n"," 'FlavaPreTrainedModel',\n"," 'FlavaProcessor',\n"," 'FlavaTextConfig',\n"," 'FlavaTextModel',\n"," 'FlaxAlbertForMaskedLM',\n"," 'FlaxAlbertForMultipleChoice',\n"," 'FlaxAlbertForPreTraining',\n"," 'FlaxAlbertForQuestionAnswering',\n"," 'FlaxAlbertForSequenceClassification',\n"," 'FlaxAlbertForTokenClassification',\n"," 'FlaxAlbertModel',\n"," 'FlaxAlbertPreTrainedModel',\n"," 'FlaxAutoModel',\n"," 'FlaxAutoModelForCausalLM',\n"," 'FlaxAutoModelForImageClassification',\n"," 'FlaxAutoModelForMaskedLM',\n"," 'FlaxAutoModelForMultipleChoice',\n"," 'FlaxAutoModelForNextSentencePrediction',\n"," 'FlaxAutoModelForPreTraining',\n"," 'FlaxAutoModelForQuestionAnswering',\n"," 'FlaxAutoModelForSeq2SeqLM',\n"," 'FlaxAutoModelForSequenceClassification',\n"," 'FlaxAutoModelForSpeechSeq2Seq',\n"," 'FlaxAutoModelForTokenClassification',\n"," 'FlaxAutoModelForVision2Seq',\n"," 'FlaxBartDecoderPreTrainedModel',\n"," 'FlaxBartForCausalLM',\n"," 'FlaxBartForConditionalGeneration',\n"," 'FlaxBartForQuestionAnswering',\n"," 'FlaxBartForSequenceClassification',\n"," 'FlaxBartModel',\n"," 'FlaxBartPreTrainedModel',\n"," 'FlaxBeitForImageClassification',\n"," 'FlaxBeitForMaskedImageModeling',\n"," 'FlaxBeitModel',\n"," 'FlaxBeitPreTrainedModel',\n"," 'FlaxBertForCausalLM',\n"," 'FlaxBertForMaskedLM',\n"," 'FlaxBertForMultipleChoice',\n"," 'FlaxBertForNextSentencePrediction',\n"," 'FlaxBertForPreTraining',\n"," 'FlaxBertForQuestionAnswering',\n"," 'FlaxBertForSequenceClassification',\n"," 'FlaxBertForTokenClassification',\n"," 'FlaxBertModel',\n"," 'FlaxBertPreTrainedModel',\n"," 'FlaxBigBirdForCausalLM',\n"," 'FlaxBigBirdForMaskedLM',\n"," 'FlaxBigBirdForMultipleChoice',\n"," 'FlaxBigBirdForPreTraining',\n"," 'FlaxBigBirdForQuestionAnswering',\n"," 'FlaxBigBirdForSequenceClassification',\n"," 'FlaxBigBirdForTokenClassification',\n"," 'FlaxBigBirdModel',\n"," 'FlaxBigBirdPreTrainedModel',\n"," 'FlaxBlenderbotForConditionalGeneration',\n"," 'FlaxBlenderbotModel',\n"," 'FlaxBlenderbotPreTrainedModel',\n"," 'FlaxBlenderbotSmallForConditionalGeneration',\n"," 'FlaxBlenderbotSmallModel',\n"," 'FlaxBlenderbotSmallPreTrainedModel',\n"," 'FlaxBloomForCausalLM',\n"," 'FlaxBloomModel',\n"," 'FlaxBloomPreTrainedModel',\n"," 'FlaxCLIPModel',\n"," 'FlaxCLIPPreTrainedModel',\n"," 'FlaxCLIPTextModel',\n"," 'FlaxCLIPTextModelWithProjection',\n"," 'FlaxCLIPTextPreTrainedModel',\n"," 'FlaxCLIPVisionModel',\n"," 'FlaxCLIPVisionPreTrainedModel',\n"," 'FlaxDistilBertForMaskedLM',\n"," 'FlaxDistilBertForMultipleChoice',\n"," 'FlaxDistilBertForQuestionAnswering',\n"," 'FlaxDistilBertForSequenceClassification',\n"," 'FlaxDistilBertForTokenClassification',\n"," 'FlaxDistilBertModel',\n"," 'FlaxDistilBertPreTrainedModel',\n"," 'FlaxElectraForCausalLM',\n"," 'FlaxElectraForMaskedLM',\n"," 'FlaxElectraForMultipleChoice',\n"," 'FlaxElectraForPreTraining',\n"," 'FlaxElectraForQuestionAnswering',\n"," 'FlaxElectraForSequenceClassification',\n"," 'FlaxElectraForTokenClassification',\n"," 'FlaxElectraModel',\n"," 'FlaxElectraPreTrainedModel',\n"," 'FlaxEncoderDecoderModel',\n"," 'FlaxForceTokensLogitsProcessor',\n"," 'FlaxForcedBOSTokenLogitsProcessor',\n"," 'FlaxForcedEOSTokenLogitsProcessor',\n"," 'FlaxGPT2LMHeadModel',\n"," 'FlaxGPT2Model',\n"," 'FlaxGPT2PreTrainedModel',\n"," 'FlaxGPTJForCausalLM',\n"," 'FlaxGPTJModel',\n"," 'FlaxGPTJPreTrainedModel',\n"," 'FlaxGPTNeoForCausalLM',\n"," 'FlaxGPTNeoModel',\n"," 'FlaxGPTNeoPreTrainedModel',\n"," 'FlaxGenerationMixin',\n"," 'FlaxLlamaForCausalLM',\n"," 'FlaxLlamaModel',\n"," 'FlaxLlamaPreTrainedModel',\n"," 'FlaxLogitsProcessor',\n"," 'FlaxLogitsProcessorList',\n"," 'FlaxLogitsWarper',\n"," 'FlaxLongT5ForConditionalGeneration',\n"," 'FlaxLongT5Model',\n"," 'FlaxLongT5PreTrainedModel',\n"," 'FlaxMBartForConditionalGeneration',\n"," 'FlaxMBartForQuestionAnswering',\n"," 'FlaxMBartForSequenceClassification',\n"," 'FlaxMBartModel',\n"," 'FlaxMBartPreTrainedModel',\n"," 'FlaxMT5EncoderModel',\n"," 'FlaxMT5ForConditionalGeneration',\n"," 'FlaxMT5Model',\n"," 'FlaxMarianMTModel',\n"," 'FlaxMarianModel',\n"," 'FlaxMarianPreTrainedModel',\n"," 'FlaxMinLengthLogitsProcessor',\n"," 'FlaxOPTForCausalLM',\n"," 'FlaxOPTModel',\n"," 'FlaxOPTPreTrainedModel',\n"," 'FlaxPegasusForConditionalGeneration',\n"," 'FlaxPegasusModel',\n"," 'FlaxPegasusPreTrainedModel',\n"," 'FlaxPreTrainedModel',\n"," 'FlaxRegNetForImageClassification',\n"," 'FlaxRegNetModel',\n"," 'FlaxRegNetPreTrainedModel',\n"," 'FlaxResNetForImageClassification',\n"," 'FlaxResNetModel',\n"," 'FlaxResNetPreTrainedModel',\n"," 'FlaxRoFormerForMaskedLM',\n"," 'FlaxRoFormerForMultipleChoice',\n"," 'FlaxRoFormerForQuestionAnswering',\n"," 'FlaxRoFormerForSequenceClassification',\n"," 'FlaxRoFormerForTokenClassification',\n"," 'FlaxRoFormerModel',\n"," 'FlaxRoFormerPreTrainedModel',\n"," 'FlaxRobertaForCausalLM',\n"," 'FlaxRobertaForMaskedLM',\n"," 'FlaxRobertaForMultipleChoice',\n"," 'FlaxRobertaForQuestionAnswering',\n"," 'FlaxRobertaForSequenceClassification',\n"," 'FlaxRobertaForTokenClassification',\n"," 'FlaxRobertaModel',\n"," 'FlaxRobertaPreLayerNormForCausalLM',\n"," 'FlaxRobertaPreLayerNormForMaskedLM',\n"," 'FlaxRobertaPreLayerNormForMultipleChoice',\n"," 'FlaxRobertaPreLayerNormForQuestionAnswering',\n"," 'FlaxRobertaPreLayerNormForSequenceClassification',\n"," 'FlaxRobertaPreLayerNormForTokenClassification',\n"," 'FlaxRobertaPreLayerNormModel',\n"," 'FlaxRobertaPreLayerNormPreTrainedModel',\n"," 'FlaxRobertaPreTrainedModel',\n"," 'FlaxSpeechEncoderDecoderModel',\n"," 'FlaxSuppressTokensAtBeginLogitsProcessor',\n"," 'FlaxSuppressTokensLogitsProcessor',\n"," 'FlaxT5EncoderModel',\n"," 'FlaxT5ForConditionalGeneration',\n"," 'FlaxT5Model',\n"," 'FlaxT5PreTrainedModel',\n"," 'FlaxTemperatureLogitsWarper',\n"," 'FlaxTopKLogitsWarper',\n"," 'FlaxTopPLogitsWarper',\n"," 'FlaxViTForImageClassification',\n"," 'FlaxViTModel',\n"," 'FlaxViTPreTrainedModel',\n"," 'FlaxVisionEncoderDecoderModel',\n"," 'FlaxVisionTextDualEncoderModel',\n"," 'FlaxWav2Vec2ForCTC',\n"," 'FlaxWav2Vec2ForPreTraining',\n"," 'FlaxWav2Vec2Model',\n"," 'FlaxWav2Vec2PreTrainedModel',\n"," 'FlaxWhisperForAudioClassification',\n"," 'FlaxWhisperForConditionalGeneration',\n"," 'FlaxWhisperModel',\n"," 'FlaxWhisperPreTrainedModel',\n"," 'FlaxWhisperTimeStampLogitsProcessor',\n"," 'FlaxXGLMForCausalLM',\n"," 'FlaxXGLMModel',\n"," 'FlaxXGLMPreTrainedModel',\n"," 'FlaxXLMRobertaForCausalLM',\n"," 'FlaxXLMRobertaForMaskedLM',\n"," 'FlaxXLMRobertaForMultipleChoice',\n"," 'FlaxXLMRobertaForQuestionAnswering',\n"," 'FlaxXLMRobertaForSequenceClassification',\n"," 'FlaxXLMRobertaForTokenClassification',\n"," 'FlaxXLMRobertaModel',\n"," 'FlaxXLMRobertaPreTrainedModel',\n"," 'FocalNetBackbone',\n"," 'FocalNetConfig',\n"," 'FocalNetForImageClassification',\n"," 'FocalNetForMaskedImageModeling',\n"," 'FocalNetModel',\n"," 'FocalNetPreTrainedModel',\n"," 'ForceTokensLogitsProcessor',\n"," 'ForcedBOSTokenLogitsProcessor',\n"," 'ForcedEOSTokenLogitsProcessor',\n"," 'FunnelBaseModel',\n"," 'FunnelConfig',\n"," 'FunnelForMaskedLM',\n"," 'FunnelForMultipleChoice',\n"," 'FunnelForPreTraining',\n"," 'FunnelForQuestionAnswering',\n"," ...]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["import transformers\n","dir(transformers)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T06:15:25.131893Z","iopub.status.busy":"2024-02-15T06:15:25.131483Z","iopub.status.idle":"2024-02-15T06:17:18.455100Z","shell.execute_reply":"2024-02-15T06:17:18.453554Z","shell.execute_reply.started":"2024-02-15T06:15:25.131864Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"231ea980f45349e5be47119b72250472","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["</s>kaz_Cyrl Іздеу кітабының атауын туған бауырлар туралы</s>\n"]}],"source":["# Load model directly\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import torch.cuda as cuda \n","device = 'cuda' if cuda.is_available() else 'cpu'\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-3.3B\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-3.3B\")\n","query = \"siblings murders\"\n","input_text = f\"Generate Research Book name on {query}\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","outputs = model.generate(input_ids)\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T05:36:49.648100Z","iopub.status.busy":"2024-02-15T05:36:49.647701Z","iopub.status.idle":"2024-02-15T05:37:02.461903Z","shell.execute_reply":"2024-02-15T05:37:02.460612Z","shell.execute_reply.started":"2024-02-15T05:36:49.648071Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1ed3b0eda67407c9b2998799af7da24","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1264f5487a6448f2924dd88725f541be","version_major":2,"version_minor":0},"text/plain":["sentencepiece.bpe.model:   0%|          | 0.00/4.85M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d13a964c60d0460f85e9fc392adea9a4","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/17.3M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e587cb9236a4f8b8249a6bfaa3b4480","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/3.55k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1ec473fc236340f380e964abfa416326","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/846 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2f08e1cfadc44f6184647137d0f79dc6","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cbaf8df5218445aab678fdd5f537e3ad","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["</s>ell_Grek Γενικεύστε το όνομα του βιβλίου έρευνας για τις δολοφονίες αδελφών</s>\n"]}],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","import torch.cuda as cuda \n","device = 'cuda' if cuda.is_available() else 'cpu'\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n","query = \"siblings murders\"\n","input_text = f\"Generate Research Book name on {query}\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","outputs = model.generate(input_ids)\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"markdown","metadata":{},"source":["#### Model : google/pegasus-multi_news"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T08:32:06.535084Z","iopub.status.busy":"2024-02-15T08:32:06.534739Z","iopub.status.idle":"2024-02-15T08:32:47.067492Z","shell.execute_reply":"2024-02-15T08:32:47.066246Z","shell.execute_reply.started":"2024-02-15T08:32:06.535059Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d746ec803edb4115b9bd3a1db8cb5c79","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--google--flan-t5-xl. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n","To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n","  warnings.warn(message)\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ae5b424f4e4439d8d1864b373738642","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e0b84b84b59446bdb7eaa4ec976c2d02","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2484b5ea33a24660892dff6bd4d38055","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a1483d8530e24ad798489bc86f38ee43","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.44k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08f7575d98d4432ba4f3df839067c0d1","version_major":2,"version_minor":0},"text/plain":["model.safetensors.index.json:   0%|          | 0.00/53.0k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d05da8ee99dd4e4c8c9f7599baee079d","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0acc2f6ec99a4a61a87e94bac6261e51","version_major":2,"version_minor":0},"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.45G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"73d8ca05e9334fd29346c5a850cd58bf","version_major":2,"version_minor":0},"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac383e2193314060915f30f190db9d62","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"93bf6144dddc4aef828882143e2c2795","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Admin\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\generation\\utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["<pad> The Sisters Murders</s>\n"]}],"source":["from transformers import AutoTokenizer,AutoModelForSeq2SeqLM\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","model_name = \"google/pegasus-multi_news\"\n","model_name = 'google/flan-t5-xl'\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","query = \"siblings murders\"\n","input_text = f\"Generate Research Book name on {query}\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","outputs = model.generate(input_ids)\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T09:29:15.197194Z","iopub.status.busy":"2024-02-15T09:29:15.196788Z","iopub.status.idle":"2024-02-15T09:29:16.343015Z","shell.execute_reply":"2024-02-15T09:29:16.341089Z","shell.execute_reply.started":"2024-02-15T09:29:15.197165Z"},"trusted":true},"outputs":[{"ename":"OSError","evalue":"You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:286\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 286\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/tokenizer_config.json","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1368\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1367\u001b[0m     \u001b[38;5;66;03m# Repo not found => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1368\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1370\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1238\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;66;03m# Cache the non-existence of the file and raise\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1631\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1631\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1633\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1640\u001b[0m hf_raise_for_status(r)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 385\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:409\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 409\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_errors.py:302\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    299\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    300\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m     )\n\u001b[0;32m--> 302\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepoNotFound\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m    305\u001b[0m     response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m\n\u001b[1;32m    306\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# => for now, we process them as `RepoNotFound` anyway.\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# See https://gist.github.com/Wauplin/46c27ad266b15998ce56a6603796f0b9\u001b[39;00m\n","\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-65cdd96b-5ea2729440b5d9342994c69b;aed333b2-e9fc-4cb7-9a2e-735fcbfa87c8)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Llama-2-7b-chat-hf/resolve/main/tokenizer_config.json.\nRepo model meta-llama/Llama-2-7b-chat-hf is gated. You must be authenticated to access it.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# from transformers import AutoTokenizer, AutoModelForCausalLM\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Load model directly\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001b[0;32m----> 6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta-llama/Llama-2-7b-chat-hf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Llama-2-7b-chat-hf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# tokenizer = AutoTokenizer.from_pretrained(model_name)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# model = AutoModelForCausalLM.from_pretrained(model_name)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:758\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    757\u001b[0m \u001b[38;5;66;03m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m tokenizer_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tokenizer_config:\n\u001b[1;32m    760\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m tokenizer_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:590\u001b[0m, in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, **kwargs)\u001b[0m\n\u001b[1;32m    587\u001b[0m     token \u001b[38;5;241m=\u001b[39m use_auth_token\n\u001b[1;32m    589\u001b[0m commit_hash \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 590\u001b[0m resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not locate the tokenizer configuration file, will try to use the model config instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:400\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m hf_hub_download(\n\u001b[1;32m    386\u001b[0m         path_or_repo_id,\n\u001b[1;32m    387\u001b[0m         filename,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    398\u001b[0m     )\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    401\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to request access at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    402\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and pass a token having permission to this repo either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby logging in with `huggingface-cli login` or by passing `token=<your_token>`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    407\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    408\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n","\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to request access at https://huggingface.co/meta-llama/Llama-2-7b-chat-hf and pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`."]}],"source":["# Load model directly\n","# from transformers import AutoTokenizer, AutoModelForCausalLM\n","# Load model directly\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-2-7b-chat-hf\")\n","\n","# tokenizer = AutoTokenizer.from_pretrained(model_name)\n","# model = AutoModelForCausalLM.from_pretrained(model_name)\n","query = \"siblings murders\"\n","input_text = f\"Generate Research Book name on {query}\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","outputs = model.generate(input_ids)\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T09:10:26.990538Z","iopub.status.busy":"2024-02-15T09:10:26.990141Z","iopub.status.idle":"2024-02-15T09:10:28.151521Z","shell.execute_reply":"2024-02-15T09:10:28.150335Z","shell.execute_reply.started":"2024-02-15T09:10:26.990507Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"966d3148b1684084b5d1489aa5a4b501","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/162 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"ename":"ValueError","evalue":"Unrecognized model in jncraton/LaMini-Flan-T5-248M-ct2-int8. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chinese_clip, clap, clip, clip_vision_model, clipseg, clvp, code_llama, codegen, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, data2vec-audio, data2vec-text, data2vec-vision, deberta, deberta-v2, decision_transformer, deformable_detr, deit, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, git, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, graphormer, groupvit, hubert, ibert, idefics, imagegpt, informer, instructblip, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, longformer, longt5, luke, lxmert, m2m_100, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mistral, mixtral, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, mpnet, mpt, mra, mt5, musicgen, mvp, nat, nezha, nllb-moe, nougat, nystromformer, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, pix2struct, plbart, poolformer, pop2piano, prophetnet, pvt, qdqbert, qwen2, rag, realm, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, umt5, unispeech, unispeech-sat, univnet, upernet, van, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      4\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjncraton/LaMini-Flan-T5-248M-ct2-int8\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext2text-generation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m input_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease let me know your thoughts on the given place and why you think it deserves to be visited: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBarcelona, Spain\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m generated_text \u001b[38;5;241m=\u001b[39m model(input_prompt, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, do_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/__init__.py:782\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    779\u001b[0m                 adapter_config \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[1;32m    780\u001b[0m                 model \u001b[38;5;241m=\u001b[39m adapter_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbase_model_name_or_path\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 782\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_from_pipeline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    785\u001b[0m     hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_commit_hash\n\u001b[1;32m    787\u001b[0m custom_tasks \u001b[38;5;241m=\u001b[39m {}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1132\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m pattern \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(pretrained_model_name_or_path):\n\u001b[1;32m   1130\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m CONFIG_MAPPING[pattern]\u001b[38;5;241m.\u001b[39mfrom_dict(config_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39munused_kwargs)\n\u001b[0;32m-> 1132\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1133\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized model in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould have a `model_type` key in its \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, or contain one of the following strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1135\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min its name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(CONFIG_MAPPING\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1136\u001b[0m )\n","\u001b[0;31mValueError\u001b[0m: Unrecognized model in jncraton/LaMini-Flan-T5-248M-ct2-int8. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: albert, align, altclip, audio-spectrogram-transformer, autoformer, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, blenderbot, blenderbot-small, blip, blip-2, bloom, bridgetower, bros, camembert, canine, chinese_clip, clap, clip, clip_vision_model, clipseg, clvp, code_llama, codegen, conditional_detr, convbert, convnext, convnextv2, cpmant, ctrl, cvt, data2vec-audio, data2vec-text, data2vec-vision, deberta, deberta-v2, decision_transformer, deformable_detr, deit, deta, detr, dinat, dinov2, distilbert, donut-swin, dpr, dpt, efficientformer, efficientnet, electra, encodec, encoder-decoder, ernie, ernie_m, esm, falcon, fastspeech2_conformer, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, git, glpn, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gptj, gptsan-japanese, graphormer, groupvit, hubert, ibert, idefics, imagegpt, informer, instructblip, jukebox, kosmos-2, layoutlm, layoutlmv2, layoutlmv3, led, levit, lilt, llama, llava, longformer, longt5, luke, lxmert, m2m_100, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mistral, mixtral, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, mpnet, mpt, mra, mt5, musicgen, mvp, nat, nezha, nllb-moe, nougat, nystromformer, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, persimmon, phi, pix2struct, plbart, poolformer, pop2piano, prophetnet, pvt, qdqbert, qwen2, rag, realm, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rwkv, sam, seamless_m4t, seamless_m4t_v2, segformer, sew, sew-d, siglip, siglip_vision_model, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, table-transformer, tapas, time_series_transformer, timesformer, timm_backbone, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, umt5, unispeech, unispeech-sat, univnet, upernet, van, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vits, vivit, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xmod, yolos, yoso"]}],"source":["# pip install -q transformers\n","from transformers import pipeline\n","\n","checkpoint = \"jncraton/LaMini-Flan-T5-248M-ct2-int8\"\n","\n","model = pipeline('text2text-generation', model = checkpoint)\n","\n","input_prompt = 'Please let me know your thoughts on the given place and why you think it deserves to be visited: \\n\"Barcelona, Spain\"'\n","generated_text = model(input_prompt, max_length=512, do_sample=True)[0]['generated_text']\n","\n","print(\"Response\", generated_text)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-02-15T10:25:32.880793Z","iopub.status.busy":"2024-02-15T10:25:32.880341Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6e64db6802c45558eb211c29ab0378e","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.50k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"729a8ddc5e00410a9e07e7f655fc9e41","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/1.89M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d5418be0178d4840aa078504f0f9d6d3","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/1.20M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3ab18e5afec049c1940032622339db1e","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/4.80M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"142ff2afe3204fe0905faaddaeb397c5","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/606 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4b26b4af19af4448b766d1b05aa64c4f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/860 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8ec0348892fd4d3786fa34e23a772c1f","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin.index.json:   0%|          | 0.00/42.1k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e32b4d8138ea48dba239f24e4e9c0742","version_major":2,"version_minor":0},"text/plain":["Downloading shards:   0%|          | 0/6 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fdefeedde9648b7b3098d58c2eda8d6","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00001-of-00006.bin:   0%|          | 0.00/9.99G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4c43026f46c4492d98c7532928efd769","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00002-of-00006.bin:   0%|          | 0.00/9.79G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a5d791d724784f3081bf0055e53ac93b","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00003-of-00006.bin:   0%|          | 0.00/9.68G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0ac5f43979304f80bc12805fcb43d57a","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00004-of-00006.bin:   0%|          | 0.00/9.68G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a8f4f65472014805a7b67308ce5dc606","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00005-of-00006.bin:   0%|          | 0.00/10.0G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"60a74927467a4ae4bed5de1590628d2b","version_major":2,"version_minor":0},"text/plain":["pytorch_model-00006-of-00006.bin:   0%|          | 0.00/5.52G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["IOPub message rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_msg_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"]}],"source":["# Load model directly\n","from transformers import AutoTokenizer, AutoModelForCausalLM\n","\n","tokenizer = AutoTokenizer.from_pretrained(\"ai-forever/mGPT-13B\")\n","model = AutoModelForCausalLM.from_pretrained(\"ai-forever/mGPT-13B\")\n","\n","import torch.cuda as cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","query = \"siblings murders\"\n","input_text = f\"Generate Research Book name on {query}\"\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(device)\n","\n","outputs = model.generate(input_ids)\n","print(tokenizer.decode(outputs[0]))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.7"}},"nbformat":4,"nbformat_minor":4}
